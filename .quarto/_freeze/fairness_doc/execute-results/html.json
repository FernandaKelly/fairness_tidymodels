{
  "hash": "45aba585892f49699b8d48b36d982ee7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Fairness\" # Título do relatório\nsubtitle: \"**Fairness com Tidymodels**\"\nauthor: \"Fernanda Kelly R. Silva | www.fernandakellyrs.com\"\nlang: pt \ndate: \"2024-04-24\" \ndate-format: short \ntoc: true \nformat: \n    html: \n      embed-resources: true\n      #css: [\"custom.css\"] \n      code-fold: false \n      code-tools: true  \n      theme: \n        light: cosmo\n        dark: superhero \n#title-block-banner: \"#874a9c\" \ncode-annotations: hover \nexecute:\n  warning: false\n  message: false\n  echo: true\n---\n\n\n\n# Universo Tidymodels\n\nOs pacotes principais do **tidymodels** trabalham juntos para permitir uma ampla variedade de abordagens de modelagem e eles são:\n\n-   **rsample** que fornece infraestrutura para divisão e reamostragem eficiente de dados;\n\n-   **parnsip** é uma interface organizada e unificada para modelos que pode ser usada para testar uma variedade de modelos sem se prender às minúcias sintáticas dos pacotes subjacentes;\n\n-   **recipes** é uma interface organizada para ferramentas de pré-processamento de dados para engenharia de recursos;\n\n-   **workflows** (fluxos de trabalho) agrupam pré-processamento, modelagem e pós-processamento;\n\n-   **tune** ajuda a otimizar os hiperparâmetros do seu modelo e as etapas de pré-processamento;\n\n-   **yardstick** (critério) mede a eficácia dos modelos usando métricas de desempenho;\n\n-   **broom** converte as informações em objetos R estatísticos comuns em formatos previsíveis e fáceis de usar;\n\n-   **dials** cria e gerencia parâmetros de ajuste e grades de parâmetros.\n\nA estrutura tidymodels também inclui muitos outros pacotes projetados para análise de dados especializada e tarefas de modelagem. Eles não são carregados automaticamente com library(tidymodels), então você precisará carregar cada um com sua própria chamada para library().\n\n# Pacote: yardstick\n\nA versão 1.3.0 do Yardstick introduziu uma implementação para **métricas de grupo**. O caso de uso que motiva a implementação desta funcionalidade são as métricas de justiça, embora as métricas de grupo tenham aplicações além desse domínio. As métricas de justiça quantificam o grau de disparidade em um valor de métrica entre grupos.\n\nA título de exemplo vamos utilizar o conjunto de dados **hpc_cv**, contendo probabilidades de classe e previsões de classe para uma análise discriminante linear ajustada ao conjunto de dados HPC de Kuhn e Johnson (2013).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(yardstick)\nlibrary(dplyr)\n```\n:::\n\n\n\n## Dados\n\nEsses dados são os conjuntos de avaliação de um esquema de validação cruzada de 10 vezes. Este quadro de dados possui as variáveis de **classe verdadeira** (obs), a **previsão da classe** (pred) e as **colunas para cada probabilidade de classe** (colunas VF, F, M e L). Além disso, é incluída uma coluna para o **indicador de reamostragem** (resample).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndados_exemplo1 <- tibble::tibble(yardstick::hpc_cv)\nhead(dados_exemplo1, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 7\n  obs   pred     VF      F       M          L Resample\n  <fct> <fct> <dbl>  <dbl>   <dbl>      <dbl> <chr>   \n1 VF    VF    0.914 0.0779 0.00848 0.0000199  Fold01  \n2 VF    VF    0.938 0.0571 0.00482 0.0000101  Fold01  \n3 VF    VF    0.947 0.0495 0.00316 0.00000500 Fold01  \n4 VF    VF    0.929 0.0653 0.00579 0.0000156  Fold01  \n5 VF    VF    0.942 0.0543 0.00381 0.00000729 Fold01  \n```\n\n\n:::\n:::\n\n\n\nPara os propósitos do exemplo, também adicionaremos uma coluna denominada por **batch** aos dados e selecionaremos as colunas para as probabilidades de classe, das quais não precisamos.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\n\nhpc <- dados_exemplo1 %>% \n       dplyr::mutate(batch = base::sample(c(\"a\", \"b\"), nrow(.), replace = TRUE)) %>% \n       select(-c(VF, F, M, L))\n```\n:::\n\n\n\n## Conscientização de grupo\n\nMesmo antes da implementação das métricas de grupo, todas as métricas de referência já tinham consciência do grupo. Quando dados agrupados são passados para uma métrica com reconhecimento de grupo, eles retornarão valores de métrica calculados para cada grupo. Logo, se temos 10 folds, e se quiséssemos calcular a precisão do modelo reamostrado, poderíamos escrever:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhpc %>% \n  dplyr::group_by(Resample) %>%\n  yardstick::accuracy(obs, pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n   Resample .metric  .estimator .estimate\n   <chr>    <chr>    <chr>          <dbl>\n 1 Fold01   accuracy multiclass     0.726\n 2 Fold02   accuracy multiclass     0.712\n 3 Fold03   accuracy multiclass     0.758\n 4 Fold04   accuracy multiclass     0.712\n 5 Fold05   accuracy multiclass     0.712\n 6 Fold06   accuracy multiclass     0.697\n 7 Fold07   accuracy multiclass     0.675\n 8 Fold08   accuracy multiclass     0.721\n 9 Fold09   accuracy multiclass     0.673\n10 Fold10   accuracy multiclass     0.699\n```\n\n\n:::\n:::\n\n\n\nVeja que aqui nós temos como produto a estimação da acurácia de cada fold ou grupo de interesse. Esse comportamento é o que entendemos por consciência de grupo.\n\n# Métricas de grupo\n\nAs métricas de grupo são associadas a uma coluna de dados de modo que, quando os dados são transmitidos a essa coluna, a métrica agrupará temporariamente por essa coluna, calculará valores para cada um dos grupos definidos pela coluna e, em seguida, agregará os valores calculados para o agrupamento temporário de volta ao nível de agrupamento dos dados de entrada.\n\nSuponha que os **batch** nos dados representem dois grupos para os quais o desempenho do modelo não deva diferir. Para quantificar o grau em que o desempenho do modelo difere para esses dois grupos, poderíamos calcular os valores de precisão para cada grupo separadamente e, em seguida, calcular a diferença. Veja o exemplo abaixo.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc_by_group <- hpc %>% \n                dplyr::filter(Resample == \"Fold01\") %>%\n                dplyr::group_by(batch) %>%\n                yardstick::accuracy(obs, pred)\nacc_by_group\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  batch .metric  .estimator .estimate\n  <chr> <chr>    <chr>          <dbl>\n1 a     accuracy multiclass     0.713\n2 b     accuracy multiclass     0.739\n```\n\n\n:::\n:::\n\n\n\nVamos observar a diferença entre os **batch**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase::diff(c(acc_by_group$.estimate[2], acc_by_group$.estimate[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.02518607\n```\n\n\n:::\n:::\n\n\n\nAs métricas de grupo codificam a função **group_by()**, etapa de agregação amostrada acima em uma métrica de critério. Podemos definir uma nova métrica groupwise com a função **new_groupwise_metric()** do pacote new_groupwise_metric.\n\nVamos entender os parâmetros dessa função?\n\n-   fn: Uma função métrica de critério ou conjunto de métricas. As métricas disponíveis no pacote são diversas, mas algumas delas são:\n\n    -   detection_prevalence\n    -   accuracy\n    -   average_precision\n    -   classification_cost\n    -   poisson_log_loss\n    -   precision\n    -   roc_auc\n    -   recall\n    -   rmse\n    -   sens\n    -   spec\n\ne você consegue ter mais informações sobre as métricas no [CRAN do pacote](https://cran.r-project.org/web/packages/yardstick/index.html).\n\n-   name: O nome da métrica a ser colocada na coluna .metric da saída.\n\n-   aggregate: Uma função para resumir os resultados do conjunto de métricas gerado. A função pega os resultados do conjunto de métricas como o primeiro argumento e retorna um único valor numérico fornecendo o valor **.estimate** como saída.\n\nNo exemplo abaixo estamos utilizando a métrica **accuracy**:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_diff <- yardstick::new_groupwise_metric(\n                               fn = accuracy,\n                               name = \"accuracy_diff\",\n                               aggregate = function(acc_by_group){\n                               base::diff(c(acc_by_group$.estimate[2], acc_by_group$.estimate[1]))  \n                               }\n)\n```\n:::\n\n\n\nVeja que a saída **accuracy_diff** é um objeto da classe **metric_factory**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(accuracy_diff)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"metric_factory\" \"function\"      \n```\n\n\n:::\n:::\n\n\n\nA partir de agora a função **accuracy_diff** sabe como obter valores de acurácia para cada grupo e depois retornar a diferença entre a acurácia do primeira e do segundo resultado como saída.\n\nA última coisa que precisamos associar ao objeto é o nome da variável de agrupamento para a qual passar **group_by()**. Podemos passar o nome da variável para **accuracy_diff** fazer isso:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy_diff_by_batch <- accuracy_diff(batch)\naccuracy_diff_by_batch\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA class metric | direction: minimize, group-wise on: batch\n```\n\n\n:::\n:::\n\n\n\nLogo, podemos usar a a**ccuracy_diff_by_batch()** como métrica da mesma forma que usaríamos **accuracy()**. Veja o exemplo abaixo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhpc %>% \n  dplyr::filter(Resample == \"Fold01\") %>%\n  accuracy_diff_by_batch(obs, pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  .metric       .by   .estimator .estimate\n  <chr>         <chr> <chr>          <dbl>\n1 accuracy_diff batch multiclass   -0.0252\n```\n\n\n:::\n:::\n\n\n\nTambém podemos adicionar **accuracy_diff_by_batch()** aos conjuntos de métricas:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc_ms <- yardstick::metric_set(accuracy, accuracy_diff_by_batch)\nacc_ms\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA metric set, consisting of:\n- `accuracy()`, a class metric               | direction: maximize\n- `accuracy_diff_by_batch()`, a class metric | direction: minimize, group-wise\non: batch\n```\n\n\n:::\n:::\n\n\n\nAplicando as métricas no **Fold01** da base de dados:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhpc %>% \n  filter(Resample == \"Fold01\") %>%\n  acc_ms(truth = obs, estimate = pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric       .estimator .estimate .by  \n  <chr>         <chr>          <dbl> <chr>\n1 accuracy      multiclass    0.726  <NA> \n2 accuracy_diff multiclass   -0.0252 batch\n```\n\n\n:::\n:::\n\n\n\nVeja que a saída **.by** nos informa que o agrupamento foi feito através do **batch**, o que nos traz como inferência que as métricas de grupo reconhecem o grupo. Quando essa operação é aplicada a dados com quaisquer variáveis com agrupamentos diferentes da coluna passada como o primeiro argumento para **accuracy_diff()**, neste caso, **accuracy_diff_by_batch()**, as métricas se comportarão como qualquer outra métrica de critério. Por exemplo:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhpc %>% \n  group_by(Resample) %>%\n  accuracy_diff_by_batch(obs, pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 5\n   Resample .metric       .by   .estimator .estimate\n   <chr>    <chr>         <chr> <chr>          <dbl>\n 1 Fold01   accuracy_diff batch multiclass -0.0252  \n 2 Fold02   accuracy_diff batch multiclass  0.106   \n 3 Fold03   accuracy_diff batch multiclass  0.0220  \n 4 Fold04   accuracy_diff batch multiclass -0.000300\n 5 Fold05   accuracy_diff batch multiclass -0.0361  \n 6 Fold06   accuracy_diff batch multiclass  0.0153  \n 7 Fold07   accuracy_diff batch multiclass -0.0323  \n 8 Fold08   accuracy_diff batch multiclass -0.0159  \n 9 Fold09   accuracy_diff batch multiclass -0.0131  \n10 Fold10   accuracy_diff batch multiclass -0.0255  \n```\n\n\n:::\n:::\n\n\n\nAs métricas de grupo formam o *back-end* das métricas de fairness em modelos organizados e, a partir dos conhecimentos adquidos até o momento, vamos estudá-los.\n\n# Métricas Fairness\n\n::: panel-tabset\n# demographic_parity()\n\nA função **demographic_parity** tem o objetivo que avaliar a paridade demográfica e essa é sastifeita quando as previsões de um modelo têm a mesma taxa positiva prevista entre os grupos.\n\nSeu único parâmetro é:\n\n-   by: O identificador de coluna do recurso confidencial. Este deve ser um nome de coluna sem aspas, referindo-se a uma coluna nos dados não pré-processados.\n\nVamos entender um pouco mais?\n\nEsta função gera uma função métrica de **critério de justiça**. Dada uma variável de agrupamento **by**, a função **demographic_parity()** retornará uma função métrica de critério, como vimos anteriormente, que está associada ao agrupamento de variáveis de dados do parâmetro **by** e a um pós-processador.\n\nA função gerada primeiro gerará um conjunto de valores de métrica de **detection_prevalence** por grupo antes de resumir entre os grupos usando a função de pós-processamento.\n\n**A função gerada possui apenas um método de quadro de dados e deve ser usada como parte de um conjunto de métricas.**\n\nPor padrão, essa função considera a diferença no intervalo da métrica **detection_prevalence** a partir do **.estimate** entre os grupos. O que significa que a disparidade entre pares entre os grupos é o valor de retorno da função.\n\nVeja o exemplo abaixo.\n\n-   (1°) Vamos atualizar o grupo de métricas:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc_ms <- yardstick::metric_set(sens, accuracy, accuracy_diff_by_batch, demographic_parity(Resample))\nacc_ms\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA metric set, consisting of:\n- `sens()`, a class metric                         | direction: maximize\n- `accuracy()`, a class metric                     | direction: maximize\n- `accuracy_diff_by_batch()`, a class metric       | direction: minimize,\ngroup-wise on: batch\n- `demographic_parity(Resample)()`, a class metric | direction: minimize,\ngroup-wise on: Resample\n```\n\n\n:::\n:::\n\n\n\nVamos utilizar a variável **Resample** como indicação de grupos.\n\n-   (2°) Aplicando a base de dados:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhpc %>%\n  acc_ms(truth = obs, estimate = pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  .metric            .estimator .estimate .by     \n  <chr>              <chr>          <dbl> <chr>   \n1 sens               macro       5.60e- 1 <NA>    \n2 accuracy           multiclass  7.09e- 1 <NA>    \n3 accuracy_diff      multiclass -6.79e- 5 batch   \n4 demographic_parity macro       2.78e-17 Resample\n```\n\n\n:::\n:::\n\n\n\nO que o resultado **.estimate** está nos contando?\n\n| .metric            | **.estimator** | **.estimate** | **.by**  |\n|:-------------------|----------------|---------------|----------|\n| demographic_parity | macro          | 2.775558e-17  | Resample |\n\n\nUm valor 0 (ou próximo de 0) indica paridade entre os grupos. Observe que esta definição não depende do verdadeiro resultado. O **truth** argumento é incluído nas métricas geradas para fins de consistência.\n\n# equal_opportunity()\n\n# equalized_odds()\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}